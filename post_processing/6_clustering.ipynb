{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 文件路径\n",
    "# input_raster = r\"D:\\UAV_DATA_NEW\\output\\2_dilated\\061301_dilated.tif\"\n",
    "# output_clustering_spectr_result = r'D:\\UAV_DATA_NEW\\output\\5_result_pixels\\061301_spec.tif'\n",
    "# output_centroid = r'D:\\UAV_DATA_NEW\\output\\5_result_centroids\\061301_spec_centroid.shp'\n",
    "\n",
    "# input_raster = r\"C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\data\\temp\\cut.tif\"\n",
    "# output_clustering_spectr_result = r'C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\data\\temp\\cut_spec.tif'\n",
    "# output_centroid = r'C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\data\\temp\\cut_spec_centroid.shp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.model = torch.load(model_path).cuda()\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, img):\n",
    "        with torch.no_grad():\n",
    "            pic_tensor = img.unsqueeze(0).unsqueeze(0).cuda()\n",
    "            return round(self.model(pic_tensor).item()) + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 0.59\n",
    "mean_area = 0.305\n",
    "size = 224\n",
    "predictor = Predictor(r'C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\output\\run\\2023-05-24_01-04-53\\model.pth')\n",
    "\n",
    "# def cut_polygon(geom):\n",
    "#     \"\"\"\n",
    "#     Cut OBB rectangle into grids\n",
    "#     \"\"\"\n",
    "#     obb = geom.minimum_rotated_rectangle.exterior.coords\n",
    "#     p1, p2, p3 = Point(obb[0]), Point(obb[1]), Point(obb[2])\n",
    "#     dist1, dist2 = p1.distance(p2), p2.distance(p3)\n",
    "#     if dist1 > dist2:\n",
    "#         cut_num = round(dist1 / interval) + int(dist1 * 2 < interval)\n",
    "#         short_edge = dist2\n",
    "#     else:\n",
    "#         cut_num = round(dist2 / interval) + int(dist2 * 2 < interval)\n",
    "#         short_edge = dist1\n",
    "#     return cut_num, short_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_raster, output_spectral_result, output_centroid):\n",
    "    src = rasterio.open(input_raster)\n",
    "\n",
    "    transform = src.transform\n",
    "    area_per_pixel = abs(transform[0] * transform[4])\n",
    "    mean_area = 0.305\n",
    "    mean_area_pixel = mean_area / area_per_pixel\n",
    "\n",
    "    img = src.read(1)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "    img_shape = img.shape\n",
    "    img = None\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    output_img = torch.zeros(img_shape, dtype=torch.uint8)\n",
    "\n",
    "    all_points = []\n",
    "\n",
    "    with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "        for i in range(1, num_labels):\n",
    "            # 获取每个连通区域的信息\n",
    "            y0, x0, h, w, num_pixels = stats[i]\n",
    "            x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "\n",
    "            if num_pixels <= 32:\n",
    "                k = 1\n",
    "            elif h >= size or w >= size:\n",
    "                k = round(num_pixels / mean_area_pixel)\n",
    "            else:\n",
    "                # 使用ResNet神经网络预测聚类数\n",
    "                image = torch.zeros((size, size), dtype=torch.float32)\n",
    "                image[x + (size - w) // 2, y + (size - h) // 2] = 1.0\n",
    "                k = predictor.predict(image)\n",
    "\n",
    "            x += x0\n",
    "            y += y0\n",
    "\n",
    "            if k == 1:\n",
    "                output_img[x, y] = 1\n",
    "                x_mean = x.float().mean()\n",
    "                y_mean = y.float().mean()\n",
    "                all_points.append(src.xy(x_mean, y_mean))  # 默认 offset='center'\n",
    "            else:\n",
    "                coords = torch.stack((x, y), dim=1)\n",
    "                cluster = SpectralClustering(n_clusters=k, affinity='rbf').fit(coords)\n",
    "\n",
    "                cluster_labels = torch.tensor(cluster.labels_, dtype=torch.uint8)\n",
    "                output_img[x, y] = cluster_labels + 1\n",
    "\n",
    "                for j in range(k):\n",
    "                    filter = torch.where(cluster_labels == j)\n",
    "                    x_mean = x[filter].float().mean()\n",
    "                    y_mean = y[filter].float().mean()\n",
    "                    all_points.append(src.xy(x_mean, y_mean))\n",
    "\n",
    "            tbar.update()\n",
    "\n",
    "    with rasterio.open(output_spectral_result, 'w', **src.meta) as dst:\n",
    "        dst.write(output_img.to(torch.uint8), 1)\n",
    "\n",
    "    geometry = gpd.GeoSeries(Point(i) for i in all_points).set_crs(src.crs)\n",
    "    geometry.to_file(output_centroid, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "061302_spec_classes_resnext50_weighted_ep50.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 170858/170858 [2:52:28<00:00, 16.51it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "061303_spec_classes_resnext50_weighted_ep50.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  17%|█▋        | 65507/378053 [1:02:41<3:02:13, 28.59it/s] "
     ]
    }
   ],
   "source": [
    "# 设置目录路径和文件后缀\n",
    "input_path = Path(r'D:\\UAV_DATA_NEW\\output\\2_dilated')\n",
    "output_path = Path(r'D:\\UAV_DATA_NEW\\output\\5_results')\n",
    "\n",
    "# 循环处理每个文件\n",
    "for input_raster in input_path.glob(f'*.tif'):\n",
    "    file_name = input_raster.stem[0:6]\n",
    "    subfolder = output_path / file_name\n",
    "    output_raster = subfolder / f'{file_name}_spec_classes_resnext50_weighted_ep50.tif'\n",
    "    output_shapefile = subfolder / f'{file_name}_spec_centroid_resnext50_weighted_ep50.shp'\n",
    "    \n",
    "    if output_raster.exists() and output_shapefile.exists():\n",
    "        continue\n",
    "    subfolder.mkdir(exist_ok=True, parents=True)\n",
    "    print(output_raster.name)\n",
    "    run(input_raster, output_raster, output_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空间谱聚类 -cpu-面积纯聚类\n",
    "img = src.read(1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "img_shape = img.shape\n",
    "img = None\n",
    "\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "output_img = torch.zeros(img_shape, dtype=torch.uint8)\n",
    "\n",
    "n_clusters = np.round(stats[:, 4] / mean_area_pixel).astype(int)\n",
    "n_clusters[n_clusters == 0] = 1\n",
    "\n",
    "all_points = []\n",
    "\n",
    "with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "    for i in range(1, num_labels):\n",
    "\n",
    "        y0, x0, h, w, _ = stats[i]\n",
    "        x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "        x += x0\n",
    "        y += y0\n",
    "\n",
    "        k = n_clusters[i]\n",
    "\n",
    "        if k <= 1:\n",
    "            output_img[x, y] = 1\n",
    "            x_mean = x.float().mean()\n",
    "            y_mean = y.float().mean()\n",
    "            all_points.append(src.xy(x_mean, y_mean))  # 默认 offset='center'\n",
    "        else:\n",
    "            coords = torch.stack((x, y), dim=1)\n",
    "            cluster = SpectralClustering(n_clusters=k, affinity='rbf').fit(coords)\n",
    "\n",
    "            cluster_labels = torch.tensor(cluster.labels_, dtype=torch.uint8)\n",
    "            output_img[x, y] = cluster_labels + 1\n",
    "\n",
    "            for j in range(k):\n",
    "                filter = torch.where(cluster_labels == j)\n",
    "                x_mean = x[filter].float().mean()\n",
    "                y_mean = y[filter].float().mean()\n",
    "                all_points.append(src.xy(x_mean, y_mean))\n",
    "\n",
    "        tbar.update()\n",
    "\n",
    "with rasterio.open(output_clustering_spectr_result, 'w', **src.meta) as dst:\n",
    "    dst.write(output_img.to(torch.uint8), 1)\n",
    "\n",
    "geometry = gpd.GeoSeries(Point(i) for i in all_points).set_crs(src.crs)\n",
    "geometry.to_file(output_centroid, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空间谱聚类 -cpu-面积纯聚类-处理点过多的情况\n",
    "src = rasterio.open(input_raster)\n",
    "img = src.read(1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "\n",
    "labels = torch.tensor(labels)\n",
    "img = torch.tensor(img)\n",
    "\n",
    "output_img = torch.zeros_like(img, dtype=torch.uint8)\n",
    "\n",
    "n_clusters = np.round(stats[:, 4] / mean_area_pixel).astype(int)\n",
    "n_clusters[n_clusters == 0] = 1\n",
    "\n",
    "all_points = []\n",
    "\n",
    "with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "    for i in range(1, num_labels):\n",
    "\n",
    "        y0, x0, h, w, _ = stats[i]\n",
    "        x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "        x += x0\n",
    "        y += y0\n",
    "\n",
    "        k = n_clusters[i]\n",
    "\n",
    "        if k <= 1:\n",
    "            output_img[x, y] = 1\n",
    "            x_mean = x.float().mean()\n",
    "            y_mean = y.float().mean()\n",
    "            point = src.xy(x_mean, y_mean)\n",
    "            all_points.append(Point(point))  # 默认 offset='center'\n",
    "        else:\n",
    "            coords = torch.stack((x, y), dim=1)\n",
    "            cluster = SpectralClustering(n_clusters=k, affinity='rbf')\n",
    "            cluster.fit(coords)\n",
    "            cluster_labels = torch.tensor(cluster.labels_, dtype=torch.uint8)\n",
    "            output_img[x, y] = cluster_labels + 1\n",
    "\n",
    "            centeroids = []\n",
    "            for j in range(k):\n",
    "                filter = torch.where(cluster_labels == j)\n",
    "                x_mean = x[filter].float().mean()\n",
    "                y_mean = y[filter].float().mean()\n",
    "\n",
    "                centroid = Point(src.xy(x_mean, y_mean))\n",
    "                distances = [centroid.distance(i) for i in centeroids]\n",
    "                if distances:\n",
    "                    min_dist = min(distances)\n",
    "                    if min_dist > 0.45:\n",
    "                        centeroids.append(centroid)\n",
    "                    else:\n",
    "\n",
    "                        point = centeroids.pop(distances.index(min_dist))\n",
    "                        new_x = (point.x + centroid.x) / 2\n",
    "                        new_y = (point.y + centroid.y) / 2\n",
    "                        centeroids.append(Point(new_x, new_y))\n",
    "                else:\n",
    "                    centeroids.append(centroid)\n",
    "\n",
    "            all_points.extend(centeroids)\n",
    "        tbar.update()\n",
    "\n",
    "with rasterio.open(output_clustering_spectr_result, 'w', **src.meta) as dst:\n",
    "    dst.write(output_img.to(torch.uint8), 1)\n",
    "\n",
    "geometry = gpd.GeoSeries(all_points).set_crs(src.crs)\n",
    "geometry.to_file(output_centroid, driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# from rtree import index\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "# # 假设你有以下的 GeoDataFrame\n",
    "# gdf = gpd.GeoDataFrame(geometry=[Point(1, 1), Point(2, 2), Point(1, 2), Point(3, 3), Point(4, 4), Point(5, 5)])\n",
    "\n",
    "# # 创建一个空的 R-tree 索引\n",
    "# idx = index.Index()\n",
    "\n",
    "# # 填充 R-tree 索引\n",
    "# for i, geom in enumerate(gdf.geometry):\n",
    "#     idx.insert(i, geom.bounds)\n",
    "\n",
    "# # 定义一个阈值，小于该阈值的点对会被选出\n",
    "# threshold = 1.5\n",
    "\n",
    "# # 查询所有距离小于阈值的点对\n",
    "# pairs = set()\n",
    "# for i in range(len(gdf)):\n",
    "#     geom = gdf.geometry[i]\n",
    "#     possible_matches_index = list(idx.nearest((geom.x, geom.y), num_results=4))  # 获得可能的匹配\n",
    "#     possible_matches = gdf.iloc[possible_matches_index]\n",
    "#     precise_matches = possible_matches[possible_matches.distance(geom) < threshold]\n",
    "\n",
    "#     for j, match in precise_matches.iterrows():\n",
    "#         if i != j:\n",
    "#             # 使用 frozenset 可以确保 (a, b) 和 (b, a) 被视为同一对\n",
    "#             pair = frozenset([geom, match.geometry])\n",
    "#             pairs.add(pair)\n",
    "\n",
    "# pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans\n",
    "with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "    for i in range(1, num_labels):\n",
    "        y0, x0, h, w, _ = stats[i]\n",
    "        x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "        x += x0\n",
    "        y += y0\n",
    "\n",
    "        coords = torch.stack((x, y), dim=1)\n",
    "        k = n_clusters[i]\n",
    "        kmeans = KMeans(n_clusters=k, n_init='auto')\n",
    "        kmeans.fit(coords)\n",
    "\n",
    "        output_img[x, y] = torch.tensor(kmeans.labels_, dtype=torch.uint8) + 1\n",
    "\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "        # if k > 2:\n",
    "        #     all_points.extend(Point(src.xy(*i)) for i in cluster_centers)\n",
    "        # else:\n",
    "        #     centeroids = []\n",
    "        #     for j in range(k):\n",
    "        #         filter = torch.where(kmeans.cluster_centers_ == j)\n",
    "\n",
    "        #         centroid = Point(src.xy(x_mean, y_mean))\n",
    "        #         distances = [centroid.distance(i) for i in centeroids]\n",
    "        #         if distances:\n",
    "        #             min_dist = min(distances)\n",
    "        #             if min_dist > 0.45:\n",
    "        #                 centeroids.append(centroid)\n",
    "        #             else:\n",
    "        #                 point = centeroids.pop(distances.index(min_dist))\n",
    "        #                 new_x = (point.x + centroid.x) / 2\n",
    "        #                 new_y = (point.y + centroid.y) / 2\n",
    "        #                 centeroids.append(Point(new_x, new_y))\n",
    "        #         else:\n",
    "        #             centeroids.append(centroid)\n",
    "\n",
    "        #     all_points.extend(centeroids)\n",
    "\n",
    "        tbar.update()\n",
    "\n",
    "with rasterio.open(output_clustering_kmeans_result, 'w', **src.meta) as dst:\n",
    "    dst.write(output_img.astype(rasterio.uint8), 1)\n",
    "\n",
    "all_centroids = np.vstack(all_points)\n",
    "\n",
    "geometry = gpd.GeoSeries(Point(i) for i in all_centroids).set_crs(src.crs)\n",
    "geometry.to_file(output_centroid, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 测量使用 + 运算符的时间\n",
    "list1 = [1, 2, 3]\n",
    "result = list1\n",
    "start_time = time.time()\n",
    "for i in range(100000):\n",
    "    result = result + [i for i in range(10)]\n",
    "end_time = time.time()\n",
    "print(\"使用 + 运算符的时间：\", end_time - start_time)\n",
    "\n",
    "# 测量使用 extend 方法的时间\n",
    "list1 = [1, 2, 3]\n",
    "start_time = time.time()\n",
    "for i in range(100000):\n",
    "    list1.extend(i for i in range(10))\n",
    "end_time = time.time()\n",
    "print(\"使用 extend 方法的时间：\", end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobacco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
