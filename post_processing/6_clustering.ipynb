{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.model = torch.load(model_path).cuda()\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, img):\n",
    "        with torch.no_grad():\n",
    "            pic_tensor = img.unsqueeze(0).unsqueeze(0).cuda()\n",
    "            return round(self.model(pic_tensor).item()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 0.62\n",
    "mean_area = 0.313748971\n",
    "size = 224\n",
    "predictor = Predictor(\n",
    "    r'C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\output\\run\\2023-05-23_13-22-00-SOTA\\model.pth')\n",
    "\n",
    "# def cut_polygon(geom):\n",
    "#     \"\"\"\n",
    "#     Cut OBB rectangle into grids\n",
    "#     \"\"\"\n",
    "#     obb = geom.minimum_rotated_rectangle.exterior.coords\n",
    "#     p1, p2, p3 = Point(obb[0]), Point(obb[1]), Point(obb[2])\n",
    "#     dist1, dist2 = p1.distance(p2), p2.distance(p3)\n",
    "#     if dist1 > dist2:\n",
    "#         cut_num = round(dist1 / interval) + int(dist1 * 2 < interval)\n",
    "#         short_edge = dist2\n",
    "#     else:\n",
    "#         cut_num = round(dist2 / interval) + int(dist2 * 2 < interval)\n",
    "#         short_edge = dist1\n",
    "#     return cut_num, short_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_raster, output_spectral_result, output_centroid):\n",
    "    src = rasterio.open(input_raster)\n",
    "\n",
    "    transform = src.transform\n",
    "    area_per_pixel = abs(transform[0] * transform[4])\n",
    "    mean_area = 0.305\n",
    "    mean_area_pixel = mean_area / area_per_pixel\n",
    "\n",
    "    img = src.read(1)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "    img_shape = img.shape\n",
    "    img = None\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    output_img = torch.zeros(img_shape, dtype=torch.uint8)\n",
    "\n",
    "    all_points = []\n",
    "\n",
    "    with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "        for i in range(1, num_labels):\n",
    "            # 获取每个连通区域的信息\n",
    "            y0, x0, h, w, num_pixels = stats[i]\n",
    "            x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "\n",
    "            if num_pixels <= 32:\n",
    "                k = 1\n",
    "            elif h >= size or w >= size:\n",
    "                k = round(num_pixels / mean_area_pixel)\n",
    "            else:\n",
    "                # 使用ResNet神经网络预测聚类数\n",
    "                image = torch.zeros((size, size), dtype=torch.float32)\n",
    "                image[x + (size - w) // 2, y + (size - h) // 2] = 1.0\n",
    "                k = predictor.predict(image)\n",
    "\n",
    "            x += x0\n",
    "            y += y0\n",
    "\n",
    "            if k == 1:\n",
    "                output_img[x, y] = 1\n",
    "                x_mean = x.float().mean()\n",
    "                y_mean = y.float().mean()\n",
    "                all_points.append(src.xy(x_mean, y_mean))  # 默认 offset='center'\n",
    "            else:\n",
    "                coords = torch.stack((x, y), dim=1)\n",
    "                cluster = SpectralClustering(n_clusters=k, affinity='rbf').fit(coords)\n",
    "\n",
    "                cluster_labels = torch.tensor(cluster.labels_, dtype=torch.uint8)\n",
    "                output_img[x, y] = cluster_labels + 1\n",
    "\n",
    "                for j in range(k):\n",
    "                    filter = torch.where(cluster_labels == j)\n",
    "                    x_mean = x[filter].float().mean()\n",
    "                    y_mean = y[filter].float().mean()\n",
    "                    all_points.append(src.xy(x_mean, y_mean))\n",
    "\n",
    "            tbar.update()\n",
    "\n",
    "    with rasterio.open(output_spectral_result, 'w', **src.meta) as dst:\n",
    "        dst.write(output_img.to(torch.uint8), 1)\n",
    "\n",
    "    geometry = gpd.GeoSeries(Point(i) for i in all_points).set_crs(src.crs)\n",
    "    geometry.to_file(output_centroid, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "061301_spec_classes_resnext50_weighted_ep50.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 179639/179639 [1:12:02<00:00, 41.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "061302_spec_classes_resnext50_weighted_ep50.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  56%|█████▌    | 95880/170858 [40:41<31:48, 39.28it/s]   \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 657. MiB for an array with shape (9278, 9278) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m subfolder\u001b[39m.\u001b[39mmkdir(exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(output_raster\u001b[39m.\u001b[39mname)\n\u001b[1;32m---> 16\u001b[0m run(input_raster, output_raster, output_shapefile)\n",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input_raster, output_spectral_result, output_centroid)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     coords \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack((x, y), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     cluster \u001b[39m=\u001b[39m SpectralClustering(n_clusters\u001b[39m=\u001b[39;49mk, affinity\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrbf\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(coords)\n\u001b[0;32m     48\u001b[0m     cluster_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(cluster\u001b[39m.\u001b[39mlabels_, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39muint8)\n\u001b[0;32m     49\u001b[0m     output_img[x, y] \u001b[39m=\u001b[39m cluster_labels \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Software\\Python\\miniconda3\\envs\\toba\\Lib\\site-packages\\sklearn\\cluster\\_spectral.py:750\u001b[0m, in \u001b[0;36mSpectralClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maffinity_matrix_ \u001b[39m=\u001b[39m pairwise_kernels(\n\u001b[0;32m    746\u001b[0m         X, metric\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maffinity, filter_params\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    747\u001b[0m     )\n\u001b[0;32m    749\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m--> 750\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_ \u001b[39m=\u001b[39m spectral_clustering(\n\u001b[0;32m    751\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maffinity_matrix_,\n\u001b[0;32m    752\u001b[0m     n_clusters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_clusters,\n\u001b[0;32m    753\u001b[0m     n_components\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[0;32m    754\u001b[0m     eigen_solver\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meigen_solver,\n\u001b[0;32m    755\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[0;32m    756\u001b[0m     n_init\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_init,\n\u001b[0;32m    757\u001b[0m     eigen_tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meigen_tol,\n\u001b[0;32m    758\u001b[0m     assign_labels\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massign_labels,\n\u001b[0;32m    759\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    760\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Software\\Python\\miniconda3\\envs\\toba\\Lib\\site-packages\\sklearn\\cluster\\_spectral.py:371\u001b[0m, in \u001b[0;36mspectral_clustering\u001b[1;34m(affinity, n_clusters, n_components, eigen_solver, random_state, n_init, eigen_tol, assign_labels, verbose)\u001b[0m\n\u001b[0;32m    363\u001b[0m n_components \u001b[39m=\u001b[39m n_clusters \u001b[39mif\u001b[39;00m n_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m n_components\n\u001b[0;32m    365\u001b[0m \u001b[39m# We now obtain the real valued solution matrix to the\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m# relaxed Ncut problem, solving the eigenvalue problem\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m# L_sym x = lambda x  and recovering u = D^-1/2 x.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[39m# The first eigenvector is constant only for fully connected graphs\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# and should be kept for spectral clustering (drop_first = False)\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# See spectral_embedding documentation.\u001b[39;00m\n\u001b[1;32m--> 371\u001b[0m maps \u001b[39m=\u001b[39m spectral_embedding(\n\u001b[0;32m    372\u001b[0m     affinity,\n\u001b[0;32m    373\u001b[0m     n_components\u001b[39m=\u001b[39;49mn_components,\n\u001b[0;32m    374\u001b[0m     eigen_solver\u001b[39m=\u001b[39;49meigen_solver,\n\u001b[0;32m    375\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[0;32m    376\u001b[0m     eigen_tol\u001b[39m=\u001b[39;49meigen_tol,\n\u001b[0;32m    377\u001b[0m     drop_first\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    378\u001b[0m )\n\u001b[0;32m    379\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m    380\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mComputing label assignment using \u001b[39m\u001b[39m{\u001b[39;00massign_labels\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Software\\Python\\miniconda3\\envs\\toba\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:248\u001b[0m, in \u001b[0;36mspectral_embedding\u001b[1;34m(adjacency, n_components, eigen_solver, random_state, eigen_tol, norm_laplacian, drop_first)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspectral_embedding\u001b[39m(\n\u001b[0;32m    145\u001b[0m     adjacency,\n\u001b[0;32m    146\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m     drop_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    153\u001b[0m ):\n\u001b[0;32m    154\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Project the sample on the first eigenvectors of the graph Laplacian.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[39m    The adjacency matrix is used to compute a normalized graph Laplacian\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39m      <10.1137/S1064827500366124>`\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m     adjacency \u001b[39m=\u001b[39m check_symmetric(adjacency)\n\u001b[0;32m    250\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mpyamg\u001b[39;00m \u001b[39mimport\u001b[39;00m smoothed_aggregation_solver\n",
      "File \u001b[1;32mc:\\Software\\Python\\miniconda3\\envs\\toba\\Lib\\site-packages\\sklearn\\utils\\validation.py:1302\u001b[0m, in \u001b[0;36mcheck_symmetric\u001b[1;34m(array, tol, raise_warning, raise_exception)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     symmetric \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mall(\u001b[39mabs\u001b[39m(diff\u001b[39m.\u001b[39mdata) \u001b[39m<\u001b[39m tol)\n\u001b[0;32m   1301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1302\u001b[0m     symmetric \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mallclose(array, array\u001b[39m.\u001b[39;49mT, atol\u001b[39m=\u001b[39;49mtol)\n\u001b[0;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m symmetric:\n\u001b[0;32m   1305\u001b[0m     \u001b[39mif\u001b[39;00m raise_exception:\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Software\\Python\\miniconda3\\envs\\toba\\Lib\\site-packages\\numpy\\core\\numeric.py:2270\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2199\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallclose\u001b[39m(a, b, rtol\u001b[39m=\u001b[39m\u001b[39m1.e-5\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1.e-8\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   2201\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2202\u001b[0m \u001b[39m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2203\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2268\u001b[0m \n\u001b[0;32m   2269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2270\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(isclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, equal_nan\u001b[39m=\u001b[39;49mequal_nan))\n\u001b[0;32m   2271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(res)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Software\\Python\\miniconda3\\envs\\toba\\Lib\\site-packages\\numpy\\core\\numeric.py:2380\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2378\u001b[0m yfin \u001b[39m=\u001b[39m isfinite(y)\n\u001b[0;32m   2379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(xfin) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(yfin):\n\u001b[1;32m-> 2380\u001b[0m     \u001b[39mreturn\u001b[39;00m within_tol(x, y, atol, rtol)\n\u001b[0;32m   2381\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2382\u001b[0m     finite \u001b[39m=\u001b[39m xfin \u001b[39m&\u001b[39m yfin\n",
      "File \u001b[1;32mc:\\Software\\Python\\miniconda3\\envs\\toba\\Lib\\site-packages\\numpy\\core\\numeric.py:2361\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[1;34m(x, y, atol, rtol)\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[0;32m   2360\u001b[0m     \u001b[39mwith\u001b[39;00m errstate(invalid\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m), _no_nep50_warning():\n\u001b[1;32m-> 2361\u001b[0m         \u001b[39mreturn\u001b[39;00m less_equal(\u001b[39mabs\u001b[39m(x\u001b[39m-\u001b[39my), atol \u001b[39m+\u001b[39m rtol \u001b[39m*\u001b[39;49m \u001b[39mabs\u001b[39;49m(y))\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 657. MiB for an array with shape (9278, 9278) and data type float64"
     ]
    }
   ],
   "source": [
    "# 设置目录路径和文件后缀\n",
    "input_path = Path(r'D:\\UAV_DATA_NEW\\output\\2_dilated')\n",
    "output_path = Path(r'D:\\UAV_DATA_NEW\\output\\5_results')\n",
    "\n",
    "# 循环处理每个文件\n",
    "for input_raster in input_path.glob(f'*.tif'):\n",
    "    file_name = input_raster.stem[0:6]\n",
    "    subfolder = output_path / file_name\n",
    "    output_raster = subfolder / f'{file_name}_spec_classes_resnext50_weighted_ep50.tif'\n",
    "    output_shapefile = subfolder / f'{file_name}_spec_centroid_resnext50_weighted_ep50.shp'\n",
    "    \n",
    "    if output_raster.exists() and output_shapefile.exists():\n",
    "        continue\n",
    "    subfolder.mkdir(exist_ok=True, parents=True)\n",
    "    print(output_raster.name)\n",
    "    run(input_raster, output_raster, output_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 文件路径\n",
    "input_raster = r\"D:\\UAV_DATA_NEW\\output\\2_dilated\\061301_dilated.tif\"\n",
    "output_clustering_spectr_result = r'D:\\UAV_DATA_NEW\\output\\5_result_pixels\\061301_spec.tif'\n",
    "output_centroid = r'D:\\UAV_DATA_NEW\\output\\5_result_centroids\\061301_spec_centroid.shp'\n",
    "\n",
    "input_raster = r\"C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\data\\temp\\cut.tif\"\n",
    "output_clustering_spectr_result = r'C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\data\\temp\\cut_spec.tif'\n",
    "output_centroid = r'C:\\Users\\xianyu\\GraduationProject\\tobacco_plant_count\\data\\temp\\cut_spec_centroid.shp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空间谱聚类 -cpu-面积纯聚类\n",
    "img = src.read(1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "img_shape = img.shape\n",
    "img = None\n",
    "\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "output_img = torch.zeros(img_shape, dtype=torch.uint8)\n",
    "\n",
    "n_clusters = np.round(stats[:, 4] / mean_area_pixel).astype(int)\n",
    "n_clusters[n_clusters == 0] = 1\n",
    "\n",
    "all_points = []\n",
    "\n",
    "with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "    for i in range(1, num_labels):\n",
    "\n",
    "        y0, x0, h, w, _ = stats[i]\n",
    "        x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "        x += x0\n",
    "        y += y0\n",
    "\n",
    "        k = n_clusters[i]\n",
    "\n",
    "        if k <= 1:\n",
    "            output_img[x, y] = 1\n",
    "            x_mean = x.float().mean()\n",
    "            y_mean = y.float().mean()\n",
    "            all_points.append(src.xy(x_mean, y_mean))  # 默认 offset='center'\n",
    "        else:\n",
    "            coords = torch.stack((x, y), dim=1)\n",
    "            cluster = SpectralClustering(n_clusters=k, affinity='rbf').fit(coords)\n",
    "\n",
    "            cluster_labels = torch.tensor(cluster.labels_, dtype=torch.uint8)\n",
    "            output_img[x, y] = cluster_labels + 1\n",
    "\n",
    "            for j in range(k):\n",
    "                filter = torch.where(cluster_labels == j)\n",
    "                x_mean = x[filter].float().mean()\n",
    "                y_mean = y[filter].float().mean()\n",
    "                all_points.append(src.xy(x_mean, y_mean))\n",
    "\n",
    "        tbar.update()\n",
    "\n",
    "with rasterio.open(output_clustering_spectr_result, 'w', **src.meta) as dst:\n",
    "    dst.write(output_img.to(torch.uint8), 1)\n",
    "\n",
    "geometry = gpd.GeoSeries(Point(i) for i in all_points).set_crs(src.crs)\n",
    "geometry.to_file(output_centroid, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空间谱聚类 -cpu-面积纯聚类-处理点过多的情况\n",
    "src = rasterio.open(input_raster)\n",
    "img = src.read(1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "\n",
    "labels = torch.tensor(labels)\n",
    "img = torch.tensor(img)\n",
    "\n",
    "output_img = torch.zeros_like(img, dtype=torch.uint8)\n",
    "\n",
    "n_clusters = np.round(stats[:, 4] / mean_area_pixel).astype(int)\n",
    "n_clusters[n_clusters == 0] = 1\n",
    "\n",
    "all_points = []\n",
    "\n",
    "with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "    for i in range(1, num_labels):\n",
    "\n",
    "        y0, x0, h, w, _ = stats[i]\n",
    "        x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "        x += x0\n",
    "        y += y0\n",
    "\n",
    "        k = n_clusters[i]\n",
    "\n",
    "        if k <= 1:\n",
    "            output_img[x, y] = 1\n",
    "            x_mean = x.float().mean()\n",
    "            y_mean = y.float().mean()\n",
    "            point = src.xy(x_mean, y_mean)\n",
    "            all_points.append(Point(point))  # 默认 offset='center'\n",
    "        else:\n",
    "            coords = torch.stack((x, y), dim=1)\n",
    "            cluster = SpectralClustering(n_clusters=k, affinity='rbf')\n",
    "            cluster.fit(coords)\n",
    "            cluster_labels = torch.tensor(cluster.labels_, dtype=torch.uint8)\n",
    "            output_img[x, y] = cluster_labels + 1\n",
    "\n",
    "            centeroids = []\n",
    "            for j in range(k):\n",
    "                filter = torch.where(cluster_labels == j)\n",
    "                x_mean = x[filter].float().mean()\n",
    "                y_mean = y[filter].float().mean()\n",
    "\n",
    "                centroid = Point(src.xy(x_mean, y_mean))\n",
    "                distances = [centroid.distance(i) for i in centeroids]\n",
    "                if distances:\n",
    "                    min_dist = min(distances)\n",
    "                    if min_dist > 0.45:\n",
    "                        centeroids.append(centroid)\n",
    "                    else:\n",
    "\n",
    "                        point = centeroids.pop(distances.index(min_dist))\n",
    "                        new_x = (point.x + centroid.x) / 2\n",
    "                        new_y = (point.y + centroid.y) / 2\n",
    "                        centeroids.append(Point(new_x, new_y))\n",
    "                else:\n",
    "                    centeroids.append(centroid)\n",
    "\n",
    "            all_points.extend(centeroids)\n",
    "        tbar.update()\n",
    "\n",
    "with rasterio.open(output_clustering_spectr_result, 'w', **src.meta) as dst:\n",
    "    dst.write(output_img.to(torch.uint8), 1)\n",
    "\n",
    "geometry = gpd.GeoSeries(all_points).set_crs(src.crs)\n",
    "geometry.to_file(output_centroid, driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# from rtree import index\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "# # 假设你有以下的 GeoDataFrame\n",
    "# gdf = gpd.GeoDataFrame(geometry=[Point(1, 1), Point(2, 2), Point(1, 2), Point(3, 3), Point(4, 4), Point(5, 5)])\n",
    "\n",
    "# # 创建一个空的 R-tree 索引\n",
    "# idx = index.Index()\n",
    "\n",
    "# # 填充 R-tree 索引\n",
    "# for i, geom in enumerate(gdf.geometry):\n",
    "#     idx.insert(i, geom.bounds)\n",
    "\n",
    "# # 定义一个阈值，小于该阈值的点对会被选出\n",
    "# threshold = 1.5\n",
    "\n",
    "# # 查询所有距离小于阈值的点对\n",
    "# pairs = set()\n",
    "# for i in range(len(gdf)):\n",
    "#     geom = gdf.geometry[i]\n",
    "#     possible_matches_index = list(idx.nearest((geom.x, geom.y), num_results=4))  # 获得可能的匹配\n",
    "#     possible_matches = gdf.iloc[possible_matches_index]\n",
    "#     precise_matches = possible_matches[possible_matches.distance(geom) < threshold]\n",
    "\n",
    "#     for j, match in precise_matches.iterrows():\n",
    "#         if i != j:\n",
    "#             # 使用 frozenset 可以确保 (a, b) 和 (b, a) 被视为同一对\n",
    "#             pair = frozenset([geom, match.geometry])\n",
    "#             pairs.add(pair)\n",
    "\n",
    "# pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans\n",
    "with tqdm(range(num_labels - 1), desc='Progress') as tbar:\n",
    "    for i in range(1, num_labels):\n",
    "        y0, x0, h, w, _ = stats[i]\n",
    "        x, y = torch.where(labels[x0:x0 + w, y0:y0 + h] == i)\n",
    "        x += x0\n",
    "        y += y0\n",
    "\n",
    "        coords = torch.stack((x, y), dim=1)\n",
    "        k = n_clusters[i]\n",
    "        kmeans = KMeans(n_clusters=k, n_init='auto')\n",
    "        kmeans.fit(coords)\n",
    "\n",
    "        output_img[x, y] = torch.tensor(kmeans.labels_, dtype=torch.uint8) + 1\n",
    "\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "        # if k > 2:\n",
    "        #     all_points.extend(Point(src.xy(*i)) for i in cluster_centers)\n",
    "        # else:\n",
    "        #     centeroids = []\n",
    "        #     for j in range(k):\n",
    "        #         filter = torch.where(kmeans.cluster_centers_ == j)\n",
    "\n",
    "        #         centroid = Point(src.xy(x_mean, y_mean))\n",
    "        #         distances = [centroid.distance(i) for i in centeroids]\n",
    "        #         if distances:\n",
    "        #             min_dist = min(distances)\n",
    "        #             if min_dist > 0.45:\n",
    "        #                 centeroids.append(centroid)\n",
    "        #             else:\n",
    "        #                 point = centeroids.pop(distances.index(min_dist))\n",
    "        #                 new_x = (point.x + centroid.x) / 2\n",
    "        #                 new_y = (point.y + centroid.y) / 2\n",
    "        #                 centeroids.append(Point(new_x, new_y))\n",
    "        #         else:\n",
    "        #             centeroids.append(centroid)\n",
    "\n",
    "        #     all_points.extend(centeroids)\n",
    "\n",
    "        tbar.update()\n",
    "\n",
    "with rasterio.open(output_clustering_kmeans_result, 'w', **src.meta) as dst:\n",
    "    dst.write(output_img.astype(rasterio.uint8), 1)\n",
    "\n",
    "all_centroids = np.vstack(all_points)\n",
    "\n",
    "geometry = gpd.GeoSeries(Point(i) for i in all_centroids).set_crs(src.crs)\n",
    "geometry.to_file(output_centroid, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 测量使用 + 运算符的时间\n",
    "list1 = [1, 2, 3]\n",
    "result = list1\n",
    "start_time = time.time()\n",
    "for i in range(100000):\n",
    "    result = result + [i for i in range(10)]\n",
    "end_time = time.time()\n",
    "print(\"使用 + 运算符的时间：\", end_time - start_time)\n",
    "\n",
    "# 测量使用 extend 方法的时间\n",
    "list1 = [1, 2, 3]\n",
    "start_time = time.time()\n",
    "for i in range(100000):\n",
    "    list1.extend(i for i in range(10))\n",
    "end_time = time.time()\n",
    "print(\"使用 extend 方法的时间：\", end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobacco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
